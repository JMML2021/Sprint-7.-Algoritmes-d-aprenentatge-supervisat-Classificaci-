{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sprint 7. Algoritmes d’aprenentatge supervisat: Classificacio.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyODtBn90/95p3k47I9WgBOE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JMML2021/Sprint-7.-Algoritmes-d-aprenentatge-supervisat-Classificaci-/blob/main/Sprint_7.2_Algoritmes_d%E2%80%99aprenentatge_supervisat_Classificacio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UfxnhLOq3ql8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "import pandas as pd  \n",
        "import seaborn as sns \n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split, cross_val_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuración warnings\n",
        "# ==============================================================================\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "T39OG7p534MA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Activo Google Drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "EtdUmEb437NJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Abro el fichero\n",
        " \n",
        "path = ('/content/drive/MyDrive/01_COLAB/wineData.txt')\n",
        "\n",
        "    \n",
        "df=  pd.read_csv(path, sep=',', encoding=\"latin-1\")\n",
        "df.shape\n",
        "\n",
        "nRow, nCol = df.shape\n",
        "print(f'Hay  {nRow} filas con {nCol} columnas')\n",
        "df1=df.copy()\n",
        "print('\\nImprimo el primer registro, solo para ver como es:\\n')\n",
        "df1.iloc[0]"
      ],
      "metadata": {
        "id": "XXfhsKL04AQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's import the data from sklearn\n",
        "from sklearn.datasets import load_wine\n",
        "wine=load_wine()\n",
        "\n",
        "#Conver to pandas dataframe\n",
        "data=pd.DataFrame(data=np.c_[wine['data'],wine['target']],columns=wine['feature_names']+['target'])\n",
        "\n",
        "#Check data with info function\n",
        "data.info()"
      ],
      "metadata": {
        "id": "oyPs6LFw7W-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Nombre_Columnas  = ['target','alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium',\n",
        "       'total_phenols', 'flavanoids', 'nonflavanoid_phenols',\n",
        "       'proanthocyanins', 'color_intensity', 'hue',\n",
        "       'od280/od315_of_diluted_wines', 'proline']"
      ],
      "metadata": {
        "id": "2F5PKNir8xAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Asigno una lista con los nombres de las columnas\n",
        "\n",
        "df1.columns = Nombre_Columnas\n",
        "df1.iloc[0]"
      ],
      "metadata": {
        "id": "U0luuEba87zN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Search for missing, NA and null values)\n",
        "\n",
        "\n",
        "(df1.isnull() | df1.empty | df1.isna()).sum()"
      ],
      "metadata": {
        "id": "zWq-5bNp8his"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.columns"
      ],
      "metadata": {
        "id": "FhtDx1sT8n8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data analysis\n",
        "Basic statistical analysis"
      ],
      "metadata": {
        "id": "bfINjK339mU6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Basic statistical analysis"
      ],
      "metadata": {
        "id": "J3jD9xUO9hCB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's show a summary of teh dataset where we can see \n",
        "# the basic statistic data.\n",
        "df1.describe()"
      ],
      "metadata": {
        "id": "GOZB0gx79uVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's see the frequency of the variable target.\n",
        "#Convert variable to categorical.\n",
        "data.target=data.target.astype('int64').astype('category')\n",
        "\n",
        "#Frequency.\n",
        "freq=df1['target'].value_counts()\n",
        "\n",
        "freq"
      ],
      "metadata": {
        "id": "Ag_DidjhAqGU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's check graphically.\n",
        "freq.plot(kind='bar')"
      ],
      "metadata": {
        "id": "u7lvQcYRAmLt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's show the histograms of the variables alcohol, magnesium y color_intensity.\n",
        "#Histogramas\n",
        " \n",
        "df1[df1.columns].hist(figsize=(18,10))"
      ],
      "metadata": {
        "id": "xzT-Oodi_Bj1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "YpIcrYo3AJKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.alldatascience.com/classification/wine-dataset-analysis-with-python/"
      ],
      "metadata": {
        "id": "4Ww7di-4AJaE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En los puntos anteriores vemos como todas las variables del conjunto de datos, excepto la variable **target**, son numéricas continuas. \n",
        "\n",
        "No faltan valores en ninguna de las variables. De los valores estadísticos básicos podemos ver que ninguna de las variables sigue una distribución normal, ya que ninguna tiene media 0 y desviación estándar 1. \n",
        "\n",
        "En los histogramas podemos observar como la variable alcohol tiene una distribución más o menos centrada, con la mayoría de las registros que tienen valores entre 12 y 14 grados, en cuanto a color_intensity y magnesio, observamos que sus distribuciones están sesgadas a la izquierda."
      ],
      "metadata": {
        "id": "EqJAAI6W_uGL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "correlation_matrix = df1.corr().round(2)\n",
        "# annot = True to print the values inside the square\n",
        "sns.set(rc = {'figure.figsize':(15,8)})\n",
        "sns.heatmap(data=correlation_matrix, annot=True)"
      ],
      "metadata": {
        "id": "47KZgIB4BjjO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PCA"
      ],
      "metadata": {
        "id": "KaAZc37eeAAG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import standardscaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "#Remove target columns.\n",
        "x = df1.loc[:,data.columns != 'target'].values\n",
        "y = df1.loc[:,['target']].values\n",
        "\n",
        "#Scale the data\n",
        "x= pd.DataFrame(StandardScaler().fit_transform(x))\n",
        "y=pd.DataFrame(y)\n",
        "# Create PCA object.\n",
        "pca = PCA(n_components=2)\n",
        "\n",
        "#Run PCA.\n",
        "pComp=pca.fit_transform(x)\n",
        "\n",
        "principalDf = pd.DataFrame(data = pComp\n",
        "             , columns = ['PC 1', 'PC 2'])\n",
        "\n",
        "principalDf.head()"
      ],
      "metadata": {
        "id": "lzjdcUxTCQaG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Join again the target variable\n",
        "\n",
        "finalDf = pd.concat([principalDf, data[['target']]], axis = 1)\n",
        "finalDf.head()"
      ],
      "metadata": {
        "id": "zZPkzUGYdp0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show the graphics.\n",
        "fig = plt.figure(figsize = (10,10))\n",
        "ax = fig.add_subplot(1,1,1) \n",
        "ax.set_xlabel('Principal Component 1', fontsize = 15)\n",
        "ax.set_ylabel('Principal Component 2', fontsize = 15)\n",
        "ax.set_title('PCA', fontsize = 20)\n",
        "targets = [0.0, 1.0, 2.0]\n",
        "colors = ['r', 'g', 'b']\n",
        "for target, color in zip(targets,colors):\n",
        "    indicesToKeep = finalDf['target'] == target\n",
        "    ax.scatter(finalDf.loc[indicesToKeep, 'PC 1']\n",
        "               , finalDf.loc[indicesToKeep, 'PC 2']\n",
        "               , c = color\n",
        "               , s = 50)\n",
        "ax.legend(targets)\n",
        "ax.grid()"
      ],
      "metadata": {
        "id": "Hjx9dE8Udk_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Normalizo los datos"
      ],
      "metadata": {
        "id": "VRL0zpXWhFAF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizo los datos para evitar que las columnas de valores grandes \n",
        "# se impongan a las columnas de valores pequeños:\n",
        "\n",
        "\n",
        "from sklearn_pandas import DataFrameMapper\n",
        "\n",
        "mapper = DataFrameMapper([(df1.columns, StandardScaler())])\n",
        "scaled_features = mapper.fit_transform(df1.copy(), 4)\n",
        "df3= pd.DataFrame(scaled_features, index=df1.index, columns=df1.columns)\n",
        "\n",
        "df3"
      ],
      "metadata": {
        "id": "xQ8QRzH-flLL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df3[df3.columns].hist(figsize=(18,10))"
      ],
      "metadata": {
        "id": "8iRiOkbpfzyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Quiero ver que variables tienen mas correlacion con respecto al target\n",
        "\n",
        "\n",
        "columns_sorted = df3.corr().abs().nlargest(4, 'target').index\n",
        "correlation_sorted = np.corrcoef(df3[columns_sorted].values.T)\n",
        "\n",
        "f, ax = plt.subplots(figsize = (9,7.5))\n",
        "hm = sns.heatmap(abs(correlation_sorted), annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=columns_sorted.values, xticklabels=columns_sorted.values, cmap='summer')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vgkwTvt6hSJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dibujar relaciones entre los datos de una manera visual de las 3 variables \n",
        "# con mas correlacion con la salida:\n",
        "\n",
        "sns.set(rc={'figure.figsize':(15, 10)})\n",
        "\n",
        "ColumnasCorrelacionAlta  = [ 'flavanoids','od280/od315_of_diluted_wines', 'total_phenols', 'target',] \n",
        "                             \n",
        "g = sns.PairGrid(df3, vars=ColumnasCorrelacionAlta, height=4, aspect=1)\n",
        "g = g.map_diag(plt.hist)\n",
        "g = g.map_lower(sns.regplot, lowess=True, scatter_kws={'s': 15, 'alpha':0.3}, \n",
        "                line_kws={'color':'red', 'linewidth': 2})\n",
        "g = g.map_upper(sns.kdeplot, n_levels=15, cmap='coolwarm')\n",
        "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
        "plt.show()"
      ],
      "metadata": {
        "id": "s9Hqy72LghnT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#scatter plots \n",
        "\n",
        "df2 = df1[['flavanoids','od280/od315_of_diluted_wines', 'total_phenols', 'target']]\n",
        "sns.pairplot(df2,hue='target')"
      ],
      "metadata": {
        "id": "ba8BCfHj_tld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nueva sección"
      ],
      "metadata": {
        "id": "L5eMbTLOuSPe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# - Exercici 1\n",
        "Crea almenys dos models de classificació diferents per intentar predir el millor les classes de l'arxiu adjunt."
      ],
      "metadata": {
        "id": "JhikyZPSkgcL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GUardaré las metricas\n",
        "\n",
        "metricasEjercicio2 = []"
      ],
      "metadata": {
        "id": "QVHiRTdJPe6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SVM Support Vector Machines con Scikit-learn"
      ],
      "metadata": {
        "id": "b_vxk6yvmju8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.datacamp.com/tutorial/svm-classification-scikit-learn-python"
      ],
      "metadata": {
        "id": "mJp7UD8kmuBo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import train_test_split function\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# Creo la columna X e Y:\n",
        "datos_x = df1.loc[:,data.columns != 'target'].values\n",
        "datos_y = df1.loc[:,['target']].values\n",
        "\n",
        "# Split dataset into training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(datos_x, datos_y, test_size=0.3,random_state=109) # 70% training and 30% test"
      ],
      "metadata": {
        "id": "VhwzRI_ikyPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Import svm model\n",
        "from sklearn import svm\n",
        "\n",
        "#Create a svm Classifier\n",
        "clf = svm.SVC(kernel='linear') # Linear Kernel\n",
        "\n",
        "#Train the model using the training sets\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "#Predict the response for test dataset\n",
        "y_pred = clf.predict(X_test)"
      ],
      "metadata": {
        "id": "sL7mvw0PlMvl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Import scikit-learn metrics module for accuracy calculation\n",
        "from sklearn import metrics\n",
        "\n",
        "# Model Accuracy: how often is the classifier correct?\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "uaWPvGOglQPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Precision: what percentage of positive tuples are labeled as such?\n",
        "print(\"Precision:\",metrics.precision_score(y_test, y_pred, pos_label='positive', average= 'micro'))\n",
        "\n",
        "# Model Recall: what percentage of positive tuples are labelled as such?\n",
        "print(\"Recall:\",metrics.recall_score(y_test, y_pred, pos_label='positive', average= 'micro'))"
      ],
      "metadata": {
        "id": "nhbr5mwFlUSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardo metricas\n",
        "metricasEjercicio2.append(['SVM', metrics.accuracy_score(y_test, y_pred), \n",
        "                           metrics.precision_score(y_test, y_pred, average='micro'),\n",
        "                           metrics.recall_score(y_test, y_pred, average='micro')])"
      ],
      "metadata": {
        "id": "c9dvpPg_Q_Es"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show the graphics.\n",
        "fig = plt.figure(figsize = (10,10))\n",
        "ax = fig.add_subplot(1,1,1) \n",
        "ax.set_xlabel('Principal Component 1', fontsize = 15)\n",
        "ax.set_ylabel('Principal Component 2', fontsize = 15)\n",
        "ax.set_title('SVM', fontsize = 20)\n",
        "targets = [0.0, 1.0, 2.0]\n",
        "colors = ['r', 'g', 'b']\n",
        "for target, color in zip(targets,colors):\n",
        "    indicesToKeep = finalDf['target'] == target\n",
        "    ax.scatter(finalDf.loc[indicesToKeep, 'PC 1']\n",
        "               , finalDf.loc[indicesToKeep, 'PC 2']\n",
        "               , c = color\n",
        "               , s = 50)\n",
        "ax.legend(targets)\n",
        "ax.grid()"
      ],
      "metadata": {
        "id": "tjyu60xmmZzR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost\n"
      ],
      "metadata": {
        "id": "uV-I1ROQuUvb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.datacamp.com/tutorial/xgboost-in-python"
      ],
      "metadata": {
        "id": "WKqJSJ43uwQM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Creo la columna X e Y:\n",
        "datos_x = df1.loc[:,data.columns != 'target'].values\n",
        "datos_y = df1.loc[:,['target']].values\n",
        "\n",
        "# Split dataset into training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(datos_x, datos_y, test_size=0.3,random_state=109) # 70% training and 30% test\n",
        "\n",
        "data_dmatrix = xgb.DMatrix(data=datos_x,label=datos_y)"
      ],
      "metadata": {
        "id": "zriff0dfuXs7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xg_reg = xgb.XGBRegressor(objective =\"reg:squarederror\", colsample_bytree = 0.3, learning_rate = 0.1,\n",
        "                max_depth = 5, alpha = 10, n_estimators = 10)"
      ],
      "metadata": {
        "id": "gwNOokwwvMHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xg_reg.fit(X_train,y_train)\n",
        "\n",
        "preds = xg_reg.predict(X_test)\n",
        "\n",
        "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
        "print(\"RMSE: %f\" % (rmse))\n",
        "\n",
        "R_squared = r2_score(y_test, preds)\n",
        "\n",
        "print(\"R-Squared: \", np.round(R_squared, 2))\n"
      ],
      "metadata": {
        "id": "iJwDJFxwvPpR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy:\", r2_score(y_test, y_pred))\n",
        "print(\"Precision:\",metrics.precision_score(y_test, y_pred, average='micro'))\n",
        "print(\"Recall:\",metrics.recall_score(y_test, y_pred, average='micro'))"
      ],
      "metadata": {
        "id": "jWD5nNPbR-Lc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardo metricas\n",
        "metricasEjercicio2.append(['XGBoost',r2_score(y_test, y_pred),0.5,0.5])"
      ],
      "metadata": {
        "id": "DCCyZRgmR-Le"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making the Prediction Error Plot\n",
        "\n",
        "from yellowbrick.regressor import residuals_plot\n",
        "from yellowbrick.regressor import prediction_error\n",
        "from sklearn.metrics import mean_squared_error as mse\n",
        "\n",
        "\n",
        "MSE = mse(y_true, y_pred)\n",
        "RMSE = np.sqrt(MSE)\n",
        "\n",
        "print(\"\\nRMSE: \", np.round(RMSE, 2))\n",
        "print()\n",
        "print(\"R-Squared: \", np.round(R_squared, 2))\n",
        "\n",
        "print(\"\\nPrediction Error Plot\")\n",
        "print(prediction_error(xg_reg, X_train, y_train, X_test, y_test))\n",
        "\n",
        "# Making the Residuals Plot\n",
        "print(\"\\nResiduals Plot\")\n",
        "\n",
        "#NO SON de la misma LONGITUD ERROR\n",
        "#print(residuals_plot(xg_reg, X_train, y_train, X_test, y_test))"
      ],
      "metadata": {
        "id": "iAanoQubAi9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BORRAR peroblemas con SIZE\n",
        "'''\n",
        "from sklearn.model_selection import train_test_split as tts\n",
        "\n",
        "# Creo la columna X e Y:\n",
        "X = df1.loc[:,data.columns != 'target'].values\n",
        "y = df1.loc[:,['target']].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = tts(X, y, test_size=0.2, shuffle=True)\n",
        "\n",
        "# Create the visualizer, fit, score, and show it\n",
        "print(residuals_plot(xg_reg, X_train, y_train, X_test, y_test))\n",
        "'''"
      ],
      "metadata": {
        "id": "e18svJ0K3aib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "id": "zqbCqVcJCPR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.scikit-yb.org/en/latest/api/regressor/residuals.html"
      ],
      "metadata": {
        "id": "kw0sxqwcDd05"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from yellowbrick.datasets import load_concrete\n",
        "from yellowbrick.regressor import ResidualsPlot\n",
        "\n",
        "\n",
        "# Creo la columna X e Y:\n",
        "datos_x = df1.loc[:,data.columns != 'target'].values\n",
        "datos_y = df1.loc[:,['target']].values\n",
        "\n",
        "# Split dataset into training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(datos_x, datos_y, test_size=0.3,random_state=109) # 70% training and 30% test\n",
        "\n",
        "\n",
        "'''\n",
        "\n",
        "# Load a regression dataset\n",
        "X, y = load_concrete()\n",
        "\n",
        "# Create the train and test data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "'''\n",
        "# Instantiate the linear model and visualizer\n",
        "model = Ridge()\n",
        "visualizer = ResidualsPlot(model)\n",
        "\n",
        "visualizer.fit(X_train, y_train)  # Fit the training data to the visualizer\n",
        "visualizer.score(X_test, y_test)  # Evaluate the model on the test data\n",
        "visualizer.show()                 # Finalize and render the figure"
      ],
      "metadata": {
        "id": "lPC31lPFDKvD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualizer = ResidualsPlot(model, hist=False)\n",
        "visualizer.fit(X_train, y_train)\n",
        "visualizer.score(X_test, y_test)\n",
        "visualizer.show()"
      ],
      "metadata": {
        "id": "M20UBERQDiEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualizer = ResidualsPlot(model, hist=False, qqplot=True)\n",
        "visualizer.fit(X_train, y_train)\n",
        "visualizer.score(X_test, y_test)\n",
        "visualizer.show()"
      ],
      "metadata": {
        "id": "UJeIAmwgDmVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\"objective\":\"reg:linear\",'colsample_bytree': 0.3,'learning_rate': 0.1,\n",
        "                'max_depth': 5, 'alpha': 10}\n",
        "\n",
        "                    num_boost_round=50,early_stopping_rounds=10,metrics=\"rmse\", as_pandas=True, seed=123)"
      ],
      "metadata": {
        "id": "4aRd_-D3v-n7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xg_reg = xgb.train(params=params, dtrain=data_dmatrix, num_boost_round=10)"
      ],
      "metadata": {
        "id": "ByDiLAhEv0DV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def report_best_scores(results, n_top=3):\n",
        "    for i in range(1, n_top + 1):\n",
        "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
        "        for candidate in candidates:\n",
        "            print(\"Model with rank: {0}\".format(i))\n",
        "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
        "                  results['mean_test_score'][candidate],\n",
        "                  results['std_test_score'][candidate]))\n",
        "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
        "            print(\"\")"
      ],
      "metadata": {
        "id": "8Il0Z3IPyJKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Buscar los mejores Hiperparametros de XGBoost:\n",
        "\n",
        "from scipy.stats import uniform, randint\n",
        "from sklearn.model_selection import cross_val_score, GridSearchCV, KFold, RandomizedSearchCV, train_test_split\n",
        "\n",
        "xgb_model = xgb.XGBRegressor(objective=\"reg:squarederror\", random_state=42)\n",
        "\n",
        "#regressor = XGBRegressor(tree_method='gpu_hist', random_state=0, objective='reg:squarederror')\n",
        "#regressor.fit(X_train, y_train)\n",
        "#xgb_model = xgb.XGBRegressor()\n",
        "\n",
        "params = {\n",
        "    \"colsample_bytree\": uniform(0.7, 0.3),\n",
        "    \"gamma\": uniform(0, 0.5),\n",
        "    \"learning_rate\": uniform(0.03, 0.3), # default 0.1 \n",
        "    \"max_depth\": randint(2, 6), # default 3\n",
        "    \"n_estimators\": randint(100, 150), # default 100\n",
        "    \"subsample\": uniform(0.6, 0.4)\n",
        "}\n",
        "\n",
        "search = RandomizedSearchCV(xgb_model, \n",
        "                            param_distributions=params, \n",
        "                            random_state=42, \n",
        "                            n_iter=200, \n",
        "                            cv=3, \n",
        "                            verbose=1, \n",
        "                            n_jobs=1, \n",
        "                            return_train_score=True)\n",
        "\n",
        "search.fit(X_train,y_train)\n",
        "\n",
        "report_best_scores(search.cv_results_, 1)"
      ],
      "metadata": {
        "id": "TcSw9p3SwzlP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Regresion Logistica"
      ],
      "metadata": {
        "id": "9SGhwusDBDAy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Regresión logística ordinal: la variable objetivo tiene tres o más categorías ordinales, como restaurante o calificación de producto de 1 a 5."
      ],
      "metadata": {
        "id": "UqnCyORDB1Ok"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import the class\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# instantiate the model (using the default parameters)\n",
        "logreg = LogisticRegression()\n",
        "\n",
        "# fit the model with data\n",
        "logreg.fit(X_train,y_train)\n",
        "\n",
        "#\n",
        "y_pred=logreg.predict(X_test)"
      ],
      "metadata": {
        "id": "Xbmwi2E0xvuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import the metrics class\n",
        "from sklearn import metrics\n",
        "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
        "cnf_matrix"
      ],
      "metadata": {
        "id": "kp0z_6pwCGWz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import required modules\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "diduZKQHCMKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names=[0,1] # name  of classes\n",
        "fig, ax = plt.subplots()\n",
        "tick_marks = np.arange(len(class_names))\n",
        "plt.xticks(tick_marks, class_names)\n",
        "plt.yticks(tick_marks, class_names)\n",
        "# create heatmap\n",
        "sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
        "ax.xaxis.set_label_position(\"top\")\n",
        "plt.tight_layout()\n",
        "plt.title('Confusion matrix', y=1.1)\n",
        "plt.ylabel('Actual label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.Text(1.5,257.44,'Predicted label')"
      ],
      "metadata": {
        "id": "a-SX8IRkCNO5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
        "print(\"Precision:\",metrics.precision_score(y_test, y_pred, average='micro'))\n",
        "print(\"Recall:\",metrics.recall_score(y_test, y_pred, average='micro'))"
      ],
      "metadata": {
        "id": "iY3hUq6wCn-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardo metricas\n",
        "metricasEjercicio2.append(['Regresion Logistica', metrics.accuracy_score(y_test, y_pred), \n",
        "                           metrics.precision_score(y_test, y_pred, average='micro'),\n",
        "                           metrics.recall_score(y_test, y_pred, average='micro')])"
      ],
      "metadata": {
        "id": "y9wlWwdsPXMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "y_pred_proba = logreg.predict_proba(X_test)[::,1]\n",
        "\n",
        "acc = metrics.accuracy_score(y_test, y_pred_proba)# To know the accuracy"
      ],
      "metadata": {
        "id": "I1MHcCvbGveW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "One-vs-the-rest (OvR) multiclass strategy.\n"
      ],
      "metadata": {
        "id": "l3AyICDVF5vk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Generamos un clasificador sin entrenar , que asignará 0 a todo\n",
        "\n",
        "# Creo la columna X e Y:\n",
        "datos_x = df1.loc[:,data.columns != 'target'].values\n",
        "datos_y = df1.loc[:,['target']].values\n",
        "\n",
        "datos_y =datos_y.astype(str)\n",
        "\n",
        "# Split dataset into training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(datos_x, datos_y, test_size=0.3,random_state=109) # 70% training and 30% test\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "trainX, testX, trainy, testy = train_test_split(X, y, test_size=0.5, random_state=2)\n",
        "\n",
        "\n",
        "ns_probs = [0 for _ in range(len(testy))]\n",
        "# Entrenamos nuestro modelo de reg log\n",
        "model = LogisticRegression(solver='lbfgs')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model.fit(trainX, trainy)\n",
        "# Predecimos las probabilidades\n",
        "lr_probs = model.predict_proba(testX)\n",
        "#Nos quedamos con las probabilidades de la clase positiva (la probabilidad de 1)\n",
        "#lr_probs = lr_probs[:, 1]\n",
        "# Calculamos el AUC\n",
        "\n",
        "#testy = lr_probs\n",
        "#ns_probs = \n",
        "\n",
        "\n",
        "\n",
        "ns_auc = roc_auc_score(testy, ns_probs, multi_class='ovo')\n",
        "\n",
        "'''\n",
        "lr_auc = roc_auc_score(testy, lr_probs)\n",
        "# Imprimimos en pantalla\n",
        "print('Sin entrenar: ROC AUC=%.3f' % (ns_auc))\n",
        "print('Regresión Logística: ROC AUC=%.3f' % (lr_auc))\n",
        "# Calculamos las curvas ROC\n",
        "ns_fpr, ns_tpr, _ = roc_curve(testy, ns_probs)\n",
        "lr_fpr, lr_tpr, _ = roc_curve(testy, lr_probs)\n",
        "# Pintamos las curvas ROC\n",
        "pyplot.plot(ns_fpr, ns_tpr, linestyle='--', label='Sin entrenar')\n",
        "pyplot.plot(lr_fpr, lr_tpr, marker='.', label='Regresión Logística')\n",
        "# Etiquetas de los ejes\n",
        "pyplot.xlabel('Tasa de Falsos Positivos')\n",
        "pyplot.ylabel('Tasa de Verdaderos Positivos')\n",
        "pyplot.legend()\n",
        "pyplot.show()\n",
        "'''"
      ],
      "metadata": {
        "id": "3vOYxrW9FE7X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Multiclass case\n",
        "\n",
        "\n",
        "# Creo la columna X e Y:\n",
        "datos_x = df1.loc[:,data.columns != 'target'].values\n",
        "datos_y = df1.loc[:,['target']].values\n",
        "\n",
        "datos_y =datos_y.astype(str)\n",
        "\n",
        "# Split dataset into training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(datos_x, datos_y, test_size=0.3,random_state=109) # 70% training and 30% test\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "clf = LogisticRegression(solver=\"liblinear\").fit(X_train, y_train)\n",
        "\n",
        "lr_probs = clf.predict_proba(X_test)\n",
        "\n",
        "ns_auc= roc_auc_score(y_test, clf.predict_proba(X_test), multi_class='ovr')\n",
        "\n",
        "# Imprimimos en pantalla\n",
        "print('Sin entrenar: ROC AUC=%.3f' % (ns_auc))\n",
        "\n",
        "#The ROC curve is created by plotting the true positive rate (TPR) against the \n",
        "# false positive rate (FPR) at various threshold settings. The true-positive rate\n",
        "#  is also known as sensitivity, recall or probability of detection.\n",
        "\n",
        "\n",
        "\n",
        "lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)\n",
        "\n",
        "\n",
        "'''\n",
        "lr_probs = model.predict_proba(X_test)\n",
        "\n",
        "\n",
        "lr_auc = roc_auc_score(y_test, lr_probs)\n",
        "\n",
        "print('Regresión Logística: ROC AUC=%.3f' % (lr_auc))\n",
        "# Calculamos las curvas ROC\n",
        "\n",
        "\n",
        "#ns_fpr, ns_tpr, _ = roc_curve(y-test, lr_probss)\n",
        "'''\n",
        "\n",
        "'''\n",
        "\n",
        "\n",
        "\n",
        "lr_fpr, lr_tpr, _ = roc_curve(testy, lr_probs)\n",
        "# Pintamos las curvas ROC\n",
        "pyplot.plot(ns_fpr, ns_tpr, linestyle='--', label='Sin entrenar')\n",
        "pyplot.plot(lr_fpr, lr_tpr, marker='.', label='Regresión Logística')\n",
        "# Etiquetas de los ejes\n",
        "pyplot.xlabel('Tasa de Falsos Positivos')\n",
        "pyplot.ylabel('Tasa de Verdaderos Positivos')\n",
        "pyplot.legend()\n",
        "pyplot.show()\n",
        "'''"
      ],
      "metadata": {
        "id": "sTGHk5lqOe5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r_aucc = roc_auc_score(y_test, lr_probs, multi_class='ovr')\n",
        "\n",
        "classes_q = sorted(np.unique(y_test))\n",
        "classes_q\n",
        "print(classes_q)\n",
        "#lr_fpr, lr_tpr, thresholds= roc_curve(y_test[0], lr_probs, pos_label=classes_q)\n"
      ],
      "metadata": {
        "id": "RLonS5LDXSjl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.kaggle.com/code/tawejssh/red-wine-quality-classification-basic-ml/notebook"
      ],
      "metadata": {
        "id": "gtUM3hYPgml6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#For ROC curves we have to binarize lables\n",
        "\n",
        "from sklearn.metrics import classification_report, roc_curve, roc_auc_score, auc, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "\n",
        "y_test_bin = label_binarize(y_test, classes=classes_q)\n",
        "y_pred_bin = label_binarize(y_pred, classes=classes_q)\n",
        "#Compute ROC curve and ROC area for each class\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "\n",
        "for i in range(len(classes_q)):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_pred_bin[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "    print(i, fpr[i], tpr[i])\n",
        "\n",
        "# Compute micro-average ROC curve and ROC area\n",
        "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test_bin.ravel(), y_pred_bin.ravel())\n",
        "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])"
      ],
      "metadata": {
        "id": "_viQ93H5f0Vv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ROC for a specific class\n",
        "lw = 2\n",
        "plt.plot(fpr[2], tpr[2], color='darkorange',\n",
        "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[2])\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver operating characteristic example')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TuCElyETgNt2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ROC for multiclass #sklearn doc\n",
        "# First aggregate all false positive rates\n",
        "\n",
        "from itertools import cycle\n",
        "\n",
        "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(len(classes_q))]))\n",
        "\n",
        "# Then interpolate all ROC curves at this points\n",
        "mean_tpr = np.zeros_like(all_fpr)\n",
        "for i in range(len(classes_q)):\n",
        "    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
        "\n",
        "# Finally average it and compute AUC\n",
        "mean_tpr /= len(classes_q)\n",
        "\n",
        "fpr[\"macro\"] = all_fpr\n",
        "tpr[\"macro\"] = mean_tpr\n",
        "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
        "\n",
        "# Plot all ROC curves\n",
        "plt.figure(figsize=(10,5))\n",
        "# plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
        "#          label='micro-average ROC curve (area = {0:0.2f})'\n",
        "#                ''.format(roc_auc[\"micro\"]),\n",
        "#          color='deeppink', linestyle=':', linewidth=4)\n",
        "\n",
        "# plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
        "#          label='macro-average ROC curve (area = {0:0.2f})'\n",
        "#                ''.format(roc_auc[\"macro\"]),\n",
        "#          color='navy', linestyle=':', linewidth=4)\n",
        "\n",
        "colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'green', 'red', 'magenta'])\n",
        "for i, color in zip(range(len(classes_q)), colors):\n",
        "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
        "             label='ROC curve of quality {0} (area = {1:0.2f})'\n",
        "             ''.format(classes_q[i], roc_auc[i]))\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "sIHgyc1JgUIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utilizando Multinomial logistic regression"
      ],
      "metadata": {
        "id": "1m5xkVoK9hIT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "log_reg = LogisticRegression(solver='newton-cg', multi_class='multinomial')\n",
        "log_reg.fit(X_train, y_train)\n",
        "y_pred = log_reg.predict(X_test)"
      ],
      "metadata": {
        "id": "PV96SpHiAtT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Accuracy: {:.2f}'.format(accuracy_score(y_test, y_pred)))\n",
        "print('Error rate: {:.2f}'.format(1 - accuracy_score(y_test, y_pred)))"
      ],
      "metadata": {
        "id": "EdWpoKwxA7t3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = LogisticRegression(solver='newton-cg', multi_class='multinomial')\n",
        "scores = cross_val_score(clf, trainX, trainY, cv=5)\n",
        "scores"
      ],
      "metadata": {
        "id": "Jv51Q9pZBNbt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Echemos un vistazo a las puntuaciones de la validación cruzada:"
      ],
      "metadata": {
        "id": "VmUw-woMBftt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = LogisticRegression(solver='newton-cg', multi_class='multinomial')\n",
        "scores = cross_val_score(clf, X_train, y_train, cv=5)\n",
        "scores"
      ],
      "metadata": {
        "id": "g-gR0ozkBgn2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
      ],
      "metadata": {
        "id": "XKGDZGLKBuaE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
        "print(confusion_matrix)\n",
        "\n",
        "plt.matshow(confusion_matrix, cmap=plt.cm.gray)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jGSO0oy7BzXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tune Penalty for Multinomial Logistic Regression"
      ],
      "metadata": {
        "id": "ebPz31BjHF8F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://machinelearningmastery.com/multinomial-logistic-regression-with-python/"
      ],
      "metadata": {
        "id": "PHFMbnVZGuYg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "...\n",
        "# define the multinomial logistic regression model\n",
        "model = LogisticRegression(multi_class='multinomial', solver='lbfgs')"
      ],
      "metadata": {
        "id": "e8KTsdp7ESHu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "# evaluate the model and collect the scores\n",
        "n_scores = cross_val_score(model, x, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "# report the model performance\n",
        "print('Mean Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
      ],
      "metadata": {
        "id": "evw3mUJ7FiW3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot\n",
        " \n",
        "# get a list of models to evaluate\n",
        "def get_models():\n",
        "\tmodels = dict()\n",
        "\tfor p in [0.0, 0.0001, 0.001, 0.01, 0.1, 1.0]:\n",
        "\t\t# create name for model\n",
        "\t\tkey = '%.4f' % p\n",
        "\t\t# turn off penalty in some cases\n",
        "\t\tif p == 0.0:\n",
        "\t\t\t# no penalty in this case\n",
        "\t\t\tmodels[key] = LogisticRegression(multi_class='multinomial', solver='lbfgs', penalty='none')\n",
        "\t\telse:\n",
        "\t\t\tmodels[key] = LogisticRegression(multi_class='multinomial', solver='lbfgs', penalty='l2', C=p)\n",
        "\treturn models\n",
        " \n",
        "# evaluate a give model using cross-validation\n",
        "def evaluate_model(model, X, y):\n",
        "\t# define the evaluation procedure\n",
        "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "\t# evaluate the model\n",
        "\tscores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "\treturn scores\n",
        " \n",
        " \n",
        "# get the models to evaluate\n",
        "models = get_models()\n",
        "# evaluate the models and store results\n",
        "results, names = list(), list()\n",
        "for name, model in models.items():\n",
        "\t# evaluate the model and collect the scores\n",
        "\tscores = evaluate_model(model, x, y)\n",
        "\t# store the results\n",
        "\tresults.append(scores)\n",
        "\tnames.append(name)\n",
        "\t# summarize progress along the way\n",
        "\tprint('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
        "# plot model performance for comparison\n",
        "pyplot.boxplot(results, labels=names, showmeans=True)\n",
        "pyplot.show()"
      ],
      "metadata": {
        "id": "qMrYLRcjEYhY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# - Exercici 2\n",
        "Compara els models de classificació utilitzant la precisió (accuracy), una matriu de confiança i d’altres mètriques més avançades."
      ],
      "metadata": {
        "id": "cF5zgmIhOvA9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df5=pd.DataFrame(metricasEjercicio2)\n",
        "df5 = df5.rename(columns = {0: 'Metodo', 1: 'Accuracy', 2: 'Precicison', 3: 'Recall'})\n",
        "print(df5)\n",
        "#plt.axhline(y=.55)\n",
        "df5.plot(kind='bar',width=0.8,\n",
        "             subplots=True,\n",
        "             figsize=(13,8))\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qt_GK5mjPoB6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# - Exercici 3\n",
        "Entrena’ls usant els diferents paràmetres que admeten per tal de millorar-ne la predicció."
      ],
      "metadata": {
        "id": "w6h1ujAgS0J-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\"objective\":\"reg:linear\",'colsample_bytree': 0.3,'learning_rate': 0.1,\n",
        "                'max_depth': 5, 'alpha': 10}\n",
        "\n",
        "                    #num_boost_round=50,early_stopping_rounds=10,metrics=\"rmse\", as_pandas=True, seed=123)"
      ],
      "metadata": {
        "id": "p3PMR_E8T-Iv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Buscar mejores parametros de XGBoost\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "6magtKKgVz09"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xg_reg = xgb.train(params=params, \n",
        "                   dtrain=data_dmatrix, \n",
        "                   num_boost_round=10)"
      ],
      "metadata": {
        "id": "HCkzHxjrT-Ix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def report_best_scores(results, n_top=3):\n",
        "    for i in range(1, n_top + 1):\n",
        "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
        "        for candidate in candidates:\n",
        "            print(\"Model with rank: {0}\".format(i))\n",
        "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
        "                  results['mean_test_score'][candidate],\n",
        "                  results['std_test_score'][candidate]))\n",
        "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
        "            print(\"\")"
      ],
      "metadata": {
        "id": "wZKinxdOT-Iy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Buscar los mejores Hiperparametros de XGBoost:\n",
        "\n",
        "from scipy.stats import uniform, randint\n",
        "from sklearn.model_selection import cross_val_score, GridSearchCV, KFold, RandomizedSearchCV, train_test_split\n",
        "\n",
        "xgb_model = xgb.XGBRegressor(objective=\"reg:squarederror\", random_state=42)\n",
        "\n",
        "#regressor = XGBRegressor(tree_method='gpu_hist', random_state=0, objective='reg:squarederror')\n",
        "#regressor.fit(X_train, y_train)\n",
        "#xgb_model = xgb.XGBRegressor()\n",
        "\n",
        "params = {\n",
        "    \"colsample_bytree\": uniform(0.7, 0.3),\n",
        "    \"gamma\": uniform(0, 0.5),\n",
        "    \"learning_rate\": uniform(0.03, 0.3), # default 0.1 \n",
        "    \"max_depth\": randint(2, 6), # default 3\n",
        "    \"n_estimators\": randint(100, 150), # default 100\n",
        "    \"subsample\": uniform(0.6, 0.4)\n",
        "}\n",
        "\n",
        "search = RandomizedSearchCV(xgb_model, \n",
        "                            param_distributions=params, \n",
        "                            random_state=42, \n",
        "                            n_iter=200, \n",
        "                            cv=3, \n",
        "                            verbose=1, \n",
        "                            n_jobs=1, \n",
        "                            return_train_score=True)\n",
        "\n",
        "search.fit(X_train,y_train)\n",
        "\n",
        "report_best_scores(search.cv_results_, 1)"
      ],
      "metadata": {
        "id": "KJZffg5HT-Iy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# - Exercici 4\n",
        "Compara el seu rendiment fent servir l’aproximació traint/test o cross-validation."
      ],
      "metadata": {
        "id": "pjdP_DqSS9Qp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_dmatrix = xgb.DMatrix(data=datos_x,label=datos_y)\n",
        "cv_results = xgb.cv(dtrain=data_dmatrix,\n",
        "                    params=params, \n",
        "                    nfold=3,\n",
        "                    num_boost_round=50,\n",
        "                    early_stopping_rounds=10,\n",
        "                    metrics=\"rmse\", \n",
        "                    as_pandas=True, \n",
        "                    seed=123)\n"
      ],
      "metadata": {
        "id": "VeuJe3NpTAX0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}